{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of image_caption_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/modinitin13/Image-caption-generator/blob/master/Image%20caption%20generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZGnv8_qhgGI",
        "colab_type": "code",
        "outputId": "3d68997f-7c97-45ed-9a5c-32d15166a542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v75KHgddel8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import load\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.merge import add\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from numpy import array\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAWwpR1UlePn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "from os import listdir\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from pickle import dump\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Input\n",
        "\n",
        "from keras.models import Model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBVkcxW8ad3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  in_layer = Input(shape=(224, 224, 3))\n",
        "  model = VGG16(include_top=False, input_tensor=in_layer, pooling='avg')\n",
        "  model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht5MbzJ_1vmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(directory):\n",
        "  count = 0\n",
        "  features= dict()\n",
        "      \n",
        "  in_layer = Input(shape=(224, 224, 3))\n",
        "  model = VGG16(include_top=False, input_tensor=in_layer, pooling='avg')\n",
        "  print(model.summary())\n",
        "  for image_name in listdir(directory):\n",
        "    filename = directory + \"/\" + image_name\n",
        "    image=load_img(filename, target_size=(224,224))\n",
        "    image=img_to_array(image)\n",
        "    image = image.reshape(1, image.shape[0], image.shape[1], image.shape[2])\n",
        "    image=preprocess_input(image)\n",
        "    feature = model.predict(image, verbose=0)\n",
        "    image_id= image_name.split(\".\")[0]\n",
        "    features[image_id]=feature\n",
        "    print(\">>> \"+ image_id)\n",
        "  print(\"done\")\n",
        "  return features\n",
        "\n",
        "directory = \"drive/My Drive/Flicker8k_Data/Flicker8k_Dataset\"\n",
        "\n",
        "features= extract_features(directory)\n",
        "print(len(features))\n",
        "\n",
        "dump(features, open('features.pkl', 'wb'))\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLIZ0larKOTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open('features.pkl', 'rb') as f:\n",
        "    features = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvRdGoypgOap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_doc(filename):\n",
        "\tfile = open(filename, 'r')\n",
        "\ttext = file.read()\n",
        "\tfile.close()\n",
        "\treturn text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u76Lt1SOKTij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvktFi7RE_O9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open('features.pkl', 'wb') as handle:\n",
        "    pickle.dump(features, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZKWQ8Q2fiVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_description(doc):\n",
        "  descriptions=dict()\n",
        "  for line in doc.split(\"\\n\"):\n",
        "    tokens = line.split()\n",
        "    if (len(line)<2):\n",
        "      continue\n",
        "    image_id, img_desc = tokens[0], tokens[1:]\n",
        "    image_id=image_id.split('.')[0]\n",
        "    img_desc=' '.join(img_desc)\n",
        "    if image_id not in descriptions:\n",
        "      descriptions[image_id]=list()\n",
        "    descriptions[image_id].append(img_desc)\n",
        "  return descriptions\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMO4dw-NfADy",
        "colab_type": "code",
        "outputId": "acba8ddf-e3a2-4957-b263-d56f3a804121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "filename = \"Flickr8k.token.txt\"\n",
        "doc = load_doc(filename)\n",
        "full_descriptions = load_description(doc)\n",
        "print(len(full_descriptions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8092\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cU77JeqftVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_descriptions(descriptions):\n",
        "  import string\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  for key, desc_list in descriptions.items():\n",
        "    for i in range(len(desc_list)):\n",
        "      desc=desc_list[i].split()\n",
        "      desc = [word.lower() for word in desc]\n",
        "      desc = [w.translate(table) for w in desc]\n",
        "      desc = [word for word in desc if len(word)>1 and word.isalpha()]\n",
        "      descriptions[key][i]= ' '.join(desc)\n",
        "  return descriptions\n",
        "      \n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8LI5UwCA9Iw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "descriptions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc8AubzrPstO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_doc(descriptions, filename):\n",
        "  lines =list()\n",
        "  for keys, desc in descriptions.items():\n",
        "    for d in desc:     \n",
        "      lines.append(keys + \" \" + d)\n",
        "    data = '\\n'.join(lines)\n",
        "    file = open(filename, 'w')\n",
        "    file.write(data)\n",
        "    file.close()\n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiYWpwn4xt25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_doc(descriptions, 'descriptions.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOLgtImEpDb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "descriptions= clean_descriptions(descriptions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMNB4_sLtxNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_vocabulary(descriptions):\n",
        "  all_words=set()\n",
        "  for keys in descriptions.keys():\n",
        "    for desc in descriptions[keys]:\n",
        "      [all_words.update(desc.split())]\n",
        "  return all_words\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9ekHvZmuqHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary = to_vocabulary(train_descriptions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8DC7glLuvXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "voc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRu5A1iWCGKp",
        "colab_type": "code",
        "outputId": "4e3d4d33-a00b-454e-a22d-48d44abbabf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocab_len"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7578"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv4x1WcZHCla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_set(filename):\n",
        "  doc = load_doc(filename)\n",
        "  dataset = list()\n",
        "  for line in doc.split('\\n'):\n",
        "    if (len(line)<1):\n",
        "      continue\n",
        "    dataset.append(line.split('.')[0])\n",
        "  return set(dataset)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oif2MV7DxsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_clean_desc(filename, dataset):\n",
        "  doc = load_doc(filename)\n",
        "  description = dict()\n",
        "  for line in doc.split('\\n'):\n",
        "    tokens = line.split()\n",
        "    image_id, img_desc = tokens[0], tokens[1:]\n",
        "    if image_id not in dataset:\n",
        "      continue\n",
        "    if image_id in dataset:\n",
        "      if image_id not in description:\n",
        "        description[image_id] = list()\n",
        "        desc = 'startseq ' + ' '.join(img_desc) + \" endseq\"\n",
        "        description[image_id].append(desc)\n",
        "  return description\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdTTpb7SFo-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_photo_features(filename, dataset):\n",
        "  \n",
        "  with open(filename, 'rb') as f:\n",
        "    all_features = pickle.load(f)\n",
        "  features =  {k:all_features[k] for k in dataset}\n",
        "  return features\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP-ClAxMHiEV",
        "colab_type": "code",
        "outputId": "b5025539-0e69-46f8-e639-15ff3f0b1c89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from pickle import load\n",
        "filename = 'drive/My Drive/Flicker8k_Data/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "train_set = load_set(filename)\n",
        "print('Dataset: %d' % len(train_set))\n",
        "train_descriptions = load_clean_desc('descriptions.txt', train_set)\n",
        "print('Descriptions: train=%d' % len(train_descriptions))\n",
        "train_features = load_photo_features('features.pkl', train_set)\n",
        "print('Photos: train=%d' % len(train_features))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 6000\n",
            "Descriptions: train=6000\n",
            "Photos: train=6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twiE4hfRDg6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features['1000268201_693b08cb0e'][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_7qRXFWbgaE",
        "colab_type": "code",
        "outputId": "91d4abba-05b5-4666-d6d2-68e5897c8fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "filename = 'drive/My Drive/Flicker8k_Data/Flickr8k_text/Flickr_8k.devImages.txt'\n",
        "dev_set = load_set(filename)\n",
        "print('Dataset: %d' % len(dev_set))\n",
        "dev_descriptions = load_clean_desc('descriptions.txt', dev_set)\n",
        "print('Descriptions: train=%d' % len(dev_descriptions))\n",
        "dev_features = load_photo_features('features.pkl', dev_set)\n",
        "print('Photos: train=%d' % len(dev_features))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 1000\n",
            "Descriptions: train=1000\n",
            "Photos: train=1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZRCYbkuJAQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_lines(descriptions):\n",
        "  all_desc = list()\n",
        "  for key in descriptions.keys():\n",
        "    [all_desc.append(d) for d in descriptions[key]]\n",
        "  return all_desc\n",
        "\n",
        "def create_tokenizer(descriptions):\n",
        "  lines = to_lines(descriptions)\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(lines)\n",
        "  return tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOc-h5rzeRDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = create_tokenizer(train_descriptions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KYL_b6DeXQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_len = len(tokenizer.word_index)+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfCabM11fGqX",
        "colab_type": "code",
        "outputId": "87650b10-1b5e-44dc-deb4-9a60796bb437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "vocab_len"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3848"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZJKbxmMezmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ddd=train_descriptions['1000268201_693b08cb0e'][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GZGv8aVfjsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kr6Z__qe1R6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_desc = to_lines(train_descriptions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2PPlKsziR3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_descriptions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CCjxW52RyNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_set= train_set|dev_set\n",
        "all_descriptions = load_clean_desc('descriptions.txt', all_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaFtRkX5R9kI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_descriptions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4CDQQWjgD7h",
        "colab_type": "code",
        "outputId": "77222188-bf87-4df2-9ce0-0551b54ba638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "def find_max_len(desc):\n",
        "  max=0\n",
        "  for key in desc.keys():\n",
        "    for sent in desc[key]:\n",
        "      if (max<len(sent.split(\" \"))):\n",
        "        max = len(sent.split(\" \"))\n",
        "  return max\n",
        "\n",
        "max_len = find_max_len(desc=all_descriptions)\n",
        "print(max_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNp80E2bBlKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bbb=tokenizer.texts_to_sequences(ddd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3eGAZ7WCO3Z",
        "colab_type": "code",
        "outputId": "ca3372e9-e9f4-470d-dae4-e48cbce6ff17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "train_features['1084104085_3b06223afe'].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "784xkA0fCPxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcFdeqBCGLEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(descriptions):\n",
        "\tlines = to_lines(descriptions)\n",
        "\treturn max(len(d.split()) for d in lines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVm-aObJGPpt",
        "colab_type": "code",
        "outputId": "080235f3-c9f8-4349-fa3d-2babd394a31b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "max_length(all_descriptions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "900W68qWGS3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_len = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odkoXMTSGdZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(vocab_len, max_len):\n",
        "  inputs1 = Input(shape = (512,))\n",
        "  fe1 = Dropout(0.5)(inputs1)\n",
        "  fe2 = Dense(256, activation='relu')(fe1)\n",
        "  \n",
        "  inputs2 = Input(shape = (max_len,))\n",
        "\n",
        "  se1 = Embedding(vocab_len, 256, mask_zero=True)(inputs2)    #mask_zero=true for padding .... 0 will be for padding\n",
        "  se2 = Dropout(0.5)(se1)\n",
        "  se3 = LSTM(256, activation = 'relu')(se2)\n",
        "  \n",
        "  decoder1 = add([fe2, se3])\n",
        "  decoder2 = Dense(256, activation = 'relu')(decoder1)\n",
        "  outputs = Dense(vocab_len, activation = 'softmax')(decoder2)\n",
        "  \n",
        "  model = Model(inputs = [inputs1, inputs2], outputs=outputs)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  \n",
        "  plot_model(model, to_file='model.png', show_shapes=True)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8-mf5FrJPbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = 'drive/My Drive/weights/image_caption/model-ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh5KhY24Jwig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model= model(vocab_len, max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKUtY49sL8Eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_sequences(tokenizer, max_len, descriptions, image_features, vocab_len):\n",
        "  X1, X2, Y = list(), list(), list()\n",
        "  for key, description in descriptions.items():\n",
        "\n",
        "    for each_desc in description:\n",
        "      seq = tokenizer.texts_to_sequences([each_desc])[0]\n",
        "      for i in range(1, len(seq)):\n",
        "        in_seq, out_seq = seq[:i], seq[i]\n",
        "        in_seq = pad_sequences([in_seq], maxlen=max_len)[0]\n",
        "        out_seq = to_categorical([out_seq], num_classes = vocab_len)[0]\n",
        "        X1.append(image_features[key])\n",
        "        X2.append(in_seq)\n",
        "        Y.append(out_seq)\n",
        "  return array(X1).reshape(-1,512), array(X2).reshape(-1,30), array(Y)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2yjjFkiL9eE",
        "colab_type": "code",
        "outputId": "b916283f-d8c0-477f-f7fd-40daa71c28b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "ytrain.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(61308, 3848)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etopTOcMKO6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1train, X2train, ytrain = create_sequences(tokenizer, max_len, descriptions=train_descriptions, image_features=train_features, vocab_len=vocab_len)\n",
        "X1test, X2test, ytest = create_sequences(tokenizer, max_len, descriptions=dev_descriptions, image_features=dev_features, vocab_len=vocab_len)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gigOQvhmVO9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUIIkB7yJm6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit([X1train, X2train], ytrain, epochs=20, verbose=1, callbacks=[checkpoint, learning_rate_reduction], validation_data=([X1test, X2test], ytest))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPQrCUw5VNx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiUCoSO88_M6",
        "colab_type": "text"
      },
      "source": [
        "# **Sampling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJoC52H49Yaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder_model():\n",
        "  in_layer = Input(shape=(224, 224, 3))\n",
        "  model = VGG16(include_top=False, input_tensor=in_layer, pooling='avg')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDHxbvjvWNkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(filenames, model):\n",
        "  count = 0\n",
        "  features= list()\n",
        "      \n",
        "  print(model.summary())\n",
        "  for filename in file_names:\n",
        "    image=load_img(filename, target_size=(224,224))\n",
        "    image=img_to_array(image)\n",
        "    image = image.reshape(1, image.shape[0], image.shape[1], image.shape[2])\n",
        "    image=preprocess_input(image)\n",
        "    feature = model.predict(image, verbose=0)\n",
        "    features.append(feature)\n",
        "    print(\">>> \"+ image_id)\n",
        "  print(\"done\")\n",
        "  print(len(features))\n",
        "  return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE0bdckdDNF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_for_id(integer, tokenizer):\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == integer:\n",
        "\t\t\treturn word\n",
        "\treturn None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAzLVchHKFdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_desc(model, tokenizer, features, max_len):\n",
        "\tin_text = 'startseq'\n",
        "\tfor i in range(max_length):\n",
        "\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\tsequence = pad_sequences([sequence], maxlen=max_length)\n",
        "\t\tyhat = model.predict([photo,sequence], verbose=0)\n",
        "\t\tyhat = argmax(yhat)\n",
        "\t\tword = word_for_id(yhat, tokenizer)\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\t\tin_text += ' ' + word\n",
        "\t\tif word == 'endseq':\n",
        "\t\t\tbreak\n",
        "\treturn in_text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcrkZxrjIszo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
        "\tactual, predicted = list(), list()\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\tyhat = generate_desc(model, tokenizer, photos[key], max_length)\n",
        "\t\treferences = [d.split() for d in desc_list]\n",
        "\t\tactual.append(references)\n",
        "\t\tpredicted.append(yhat.split())\n",
        "\tprint('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "\tprint('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "\tprint('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "\tprint('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q1BwMZAwNdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'drive/My Drive/Flicker8k_Data/Flickr8k_text/Flickr_8k.testImages.txt'\n",
        "test = load_set(filename)\n",
        "print('Dataset: %d' % len(test))\n",
        "# descriptions\n",
        "test_descriptions = load_clean_descriptions('descriptions.txt', test)\n",
        "print('Descriptions: test=%d' % len(test_descriptions))\n",
        "# photo features\n",
        "test_features = load_photo_features('features.pkl', test)\n",
        "print('Photos: test=%d' % len(test_features))\n",
        "\n",
        "# evaluate model\n",
        "evaluate_model(model, test_descriptions, test_features, tokenizer, max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}